{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Gradient Descent - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we derived the functions that we help us descend along our cost functions efficiently.  Remember that this technique is not so different from what we saw with using the derivative to tell us our next step size and direction in two dimensions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./slopes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When descending along our cost curve in two dimensions, we used the slope of the tangent line at each point, to tell us how large of a step to take next.  And with the our cost curve being a function of $m$ and $b$, we had to use the gradient to determine each step.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./gradientdescent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But really it's an analogous approach.  Just like we can calculate the use derivative of a function $f(x)$ to calculate the slope at a given value of $x$ on the graph, and thus our next step.  Here, we calculated the partial derivative with respect to both variables, our slope and y-intercept, to calculate the amount to move next in either direction, and thus to steer us towards our minimum.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "- Create a full gradient descent algorithm\n",
    "- Apply a gradient descent algorithm on a data set with more than one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing our gradient descent formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, we already did the hard work of deriving these formulas.  Now we get to see the fruit of our labor.  The following formulas tell us how to update regression variables of $m$ and $b$ to approach a \"best fit\" line.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ \\frac{dJ}{dm}J(m,b) = -2\\sum_{i = 1}^n x_i(y_i - (mx_i + b)) = -2\\sum_{i = 1}^n x_i*\\epsilon_i$ \n",
    "* $ \\frac{dJ}{db}J(m,b) = -2\\sum_{i = 1}^n(y_i - (mx_i + b)) = -2\\sum_{i = 1}^n \\epsilon_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the formulas above tell us to take some dataset, with values of $x$ and $y$, and then given a regression formula with values $m$ and $b$, iterate through our dataset, and use the formulas to calculate an update to $m$ and $b$.  So ultimately, to descend along the cost function, we will use the calculations:\n",
    "\n",
    "`current_m` = `old_m` $ -  (-2*\\sum_{i=1}^n x_i*\\epsilon_i )$\n",
    "\n",
    "`current_b` =  `old_b` $ - ( -2*\\sum_{i=1}^n \\epsilon_i )$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok let's turn this into code.  First, let's initialize our data like we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(225)\n",
    "\n",
    "x = np.random.rand(30, 1).reshape(30)\n",
    "y_randterm = np.random.normal(0,3,30)\n",
    "y = 3 + 50* x + y_randterm\n",
    "\n",
    "data = np.array([y, x])\n",
    "data = np.transpose(data)\n",
    "\n",
    "plt.plot(x, y, '.b')\n",
    "plt.xlabel(\"x\", fontsize=14)\n",
    "plt.ylabel(\"y\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now\n",
    "\n",
    "- Let's set our initial regression line by initializing $m$ and $b$ variables as zero.  Store them in `b_current` and `m_current`.\n",
    "- Let's next initialize updates to these variables by setting to variables, `update_to_b` and `update_to_m` equal to 0.\n",
    "- Define an `error_at` function which outputs the error $\\epsilon_i$ for a given $i$. inputs are a row of the particular data set, $b$ and $m$.\n",
    "- Them, use this `error_at` function to iterate through each of the points in the dataset, and at each iteration change our `update_to_b` by $2*\\epsilon$ and change our `update_to_m` by $2*x*\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial variables of our regression line\n",
    "b_current = 0\n",
    "m_current = 0\n",
    "\n",
    "#amount to update our variables for our next step\n",
    "update_to_b = 0\n",
    "update_to_m = 0\n",
    "\n",
    "# Define the error_at function\n",
    "def error_at(point, b, m):\n",
    "    return (point[0] - (m*point[1] + b))\n",
    "\n",
    "# iterate through data to change update_to_b and update_to_m\n",
    "for i in range(0, len(data)):\n",
    "    update_to_b += -2*(error_at(data[i], b_current, m_current))\n",
    "    update_to_m += -2*(error_at(data[i], b_current, m_current))*data[i][1]\n",
    "    \n",
    "# Create new_b and new_m by subtracting the updates from the current estimates\n",
    "new_b = b_current - update_to_b\n",
    "new_m = m_current - update_to_m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last two lines of the code above, we calculate our `new_b` and `new_m` values by updating our taking our current values and adding our respective updates.  We define a function called `error_at`, which we can use in the error component of our partial derivatives above.\n",
    "\n",
    "The code above represents **just one** update to our regression line, and therefore just one step towards our best fit line.  We'll just repeat the process to take multiple steps.  But first we have to make a couple other changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking our approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the above code is very close to what we want, but we just need to make tweaks to our code before it's perfect.\n",
    "\n",
    "The first one is obvious if we think about what these formulas are really telling us to do.  Look at the graph below, and think about what it means to change each of our $m$ and $b$ variables by at least the sum of all of the errors, of the $y$ values that our regression line predicts and our actual data.  That would be an enormous change.  To ensure that we drastically updating our regression line with each step, we multiply each of these partial derivatives by a learning rate.  As we have seen before, the learning rate is just a small number, like $.\n",
    "01$ which controls for how large our updates to the regression line will be.  The learning rate is  represented by the Greek letter eta, $\\eta$, or alpha $\\alpha$.  We'll use eta, so $\\eta = .01$ means the learning rate is $.01$.\n",
    "\n",
    "Multiplying our step size by our learning rate works fine, so long as we multiply both of the partial derivatives by the same amount.  This is because with out gradient,  $ \\nabla J(m,b)$, we think of as steering us in the correct direction.  In other words, our derivatives ensure we are make the correct **proportional** changes to $m$ and $b$.  So scaling down these changes to make sure we don't update our regression line too quickly works fine, so long as we keep me moving in the correct direction.  While were at it, we can also get rid of multiplying our partials by 2.  As mentioned, so long as our changes are proportional we're in good shape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our second tweak, note that in general the larger the dataset, the larger the sum of our errors would be.  But that doesn't mean our formulas are less accurate, and there deserve larger changes.  It just means that the total error is larger.  But we should really think accuracy as being proportional to the size of our dataset.  We can correct for this effect by dividing the effect of our update by the size of our dataset, $n$.\n",
    "\n",
    "Make these changes below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amount to update our variables for our next step\n",
    "update_to_b = 0\n",
    "update_to_m = 0\n",
    "\n",
    "# define learning rate and n\n",
    "learning_rate = 0.01\n",
    "n = len(data)\n",
    "\n",
    "# create update_to_b and update_to_m\n",
    "for i in range(0,n):\n",
    "    update_to_b += -(1/n)*(error_at(data[i], b_current, m_current))\n",
    "    update_to_m += -(1/n)*(error_at(data[i], b_current, m_current))*data[i][0]\n",
    "    \n",
    "# create new_b and new_m\n",
    "new_b = b_current - (learning_rate * update_to_b)\n",
    "new_m = m_current - (learning_rate * update_to_m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our code now reflects what we know about our gradient descent process.  Start with an initial regression line with values of $m$ and $b$.  Then for each point, calculate how the regression line fares against the actual point (that is, find the error).  Update what our next step to the respective variable should be using by using the partial derivative.  And after iterating through all of the points, update the value of $b$ and $m$ appropriately, scaled down by a learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing our gradient descent formulas in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, the code above represents just one update to our regression line, and therefore just one step towards our best fit line.  To take multiple steps we wrap the process we want to duplicate in a function called `step_gradient` and then can call that function as much as we want. In what's next:\n",
    "\n",
    "- Let's make sure to include a learning_rate of 0.1\n",
    "- Let's output new_b and new_m as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(b_current, m_current, points):\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    learning_rate = 0.1\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i][1]\n",
    "        y = points[i][0]\n",
    "        b_gradient += -(1/N)*(y - (m_current * x + b_current))\n",
    "        m_gradient += -(1/N)*x*(y - (m_current * x + b_current))\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = b_current - (learning_rate * m_gradient)\n",
    "    return (new_b, new_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's initialize `b` and `m` as 0 and run a first iteration of the `step_gradient` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new b 3.0250308395837813\n",
      "new m 2.0728619246505193\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "m = 0\n",
    "first_step = step_gradient(b,m,data)\n",
    "print('new b', first_step[0])\n",
    "print('new m', first_step[1])\n",
    "# b= 3.02503, m= 2.07286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So just looking at input and output, we begin by setting $b$ and $m$ to 0 amnd 0.  Then from our step_gradient function, we receive new values of $b$ and $m$ of 3.02503 and 2.0728.  Now what we need to do, is take another step in the correct direction by calling our step gradient function with our updated values of $b$ and $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new b 5.634896312558807\n",
      "new m 4.854434563837228\n"
     ]
    }
   ],
   "source": [
    "updated_b = first_step[0]\n",
    "updated_m = first_step[1]\n",
    "second_step = step_gradient(updated_b, updated_m, data)\n",
    "print('new b', second_step[0])\n",
    "print('new m', second_step[1])\n",
    "# b = 5.63489, m= 3.902265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this, say, 1000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a for loop to do this\n",
    "b = 0\n",
    "m = 0\n",
    "iterations = []\n",
    "for i in range(1000):\n",
    "    iteration = step_gradient(b,m,data)\n",
    "    b = iteration[0]\n",
    "    m = iteration[1]\n",
    "    iterations.append(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the estimates in the last iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.0250308395837813, 2.0728619246505193),\n",
       " (5.634896312558807, 4.854434563837228),\n",
       " (7.83259376340585, 7.216381233944287),\n",
       " (9.682147118620174, 9.20456326915196),\n",
       " (11.238685299040974, 10.877775994742029),\n",
       " (12.54862874404218, 12.285909971203534),\n",
       " (13.65104424325554, 13.470960158604912),\n",
       " (14.578809435948688, 14.468268629253712),\n",
       " (15.359593317691186, 15.307578386875393),\n",
       " (16.016681420144327, 16.013920396363677),\n",
       " (16.56967026184773, 16.608360089024576),\n",
       " (17.035051780561616, 17.108625602705093),\n",
       " (17.426705176845893, 17.529636492906185),\n",
       " (17.75631083726171, 17.883948682774857),\n",
       " (18.033698681740642, 18.182128921840814),\n",
       " (18.267141323980457, 18.433069921083273),\n",
       " (18.46360078787036, 18.64425556268737),\n",
       " (18.628936137837215, 18.82198409391331),\n",
       " (18.768078215329506, 18.971555961450342),\n",
       " (18.885176692653033, 19.097431888090814),\n",
       " (18.983723829785205, 19.203365906088376),\n",
       " (19.066658625001335, 19.2925173146906),\n",
       " (19.136454465425558, 19.36754490078616),\n",
       " (19.195192891532823, 19.430686232634795),\n",
       " (19.244625675500867, 19.483824391478688),\n",
       " (19.286227064791905, 19.528544131190355),\n",
       " (19.321237749038687, 19.566179140821646),\n",
       " (19.35070186147139, 19.597851819577823),\n",
       " (19.37549811838907, 19.624506750436613),\n",
       " (19.396366025356638, 19.646938870705203),\n",
       " (19.413927931681968, 19.66581717965337),\n",
       " (19.42870759090984, 19.681704690262062),\n",
       " (19.441145780867444, 19.695075220113768),\n",
       " (19.451613449102286, 19.706327522184147),\n",
       " (19.460422775752562, 19.715797176961285),\n",
       " (19.467836483780964, 19.72376660055454),\n",
       " (19.47407567423358, 19.730473467267586),\n",
       " (19.479326420196987, 19.736117797824264),\n",
       " (19.4837453161069, 19.74086792464147),\n",
       " (19.48746414790694, 19.744865512052932),\n",
       " (19.490593823336944, 19.748229781203477),\n",
       " (19.493227679564875, 19.751061065613886),\n",
       " (19.495444266806764, 19.753443803454974),\n",
       " (19.497309690951337, 19.75544905577031),\n",
       " (19.498879585054034, 19.757136625749197),\n",
       " (19.50020076849687, 19.758556842253547),\n",
       " (19.50131264329571, 19.759752060789353),\n",
       " (19.502248369197353, 19.76075792668653),\n",
       " (19.503035852611784, 19.761604438159363),\n",
       " (19.503698578872662, 19.762316840951474),\n",
       " (19.504256312646874, 19.762916381246548),\n",
       " (19.504725687381598, 19.7634209392991),\n",
       " (19.50512070136817, 19.76384556268219),\n",
       " (19.50545313521696, 19.764202915055332),\n",
       " (19.505732903193735, 19.764503653836275),\n",
       " (19.505968348895525, 19.764756748040096),\n",
       " (19.50616649408402, 19.764969745764585),\n",
       " (19.50633324809747, 19.76514899929925),\n",
       " (19.506473584086514, 19.765299854571374),\n",
       " (19.50659168732981, 19.765426810579076),\n",
       " (19.506691080052747, 19.765533653566166),\n",
       " (19.506774726471736, 19.765623569940324),\n",
       " (19.506845121196854, 19.76569924130222),\n",
       " (19.506904363629275, 19.765762924419608),\n",
       " (19.506954220572297, 19.76581651853155),\n",
       " (19.506996178923192, 19.76586162198994),\n",
       " (19.507031490017358, 19.76589957992757),\n",
       " (19.507061206947235, 19.76593152437442),\n",
       " (19.50708621596896, 19.76595840801848),\n",
       " (19.50710726293345, 19.765981032618033),\n",
       " (19.507124975530083, 19.766000072912714),\n",
       " (19.50713988200649, 19.766016096746444),\n",
       " (19.5071524269226, 19.76602958200241),\n",
       " (19.507162984408886, 19.766040930855098),\n",
       " (19.50717186932415, 19.76605048176445),\n",
       " (19.507179346645657, 19.76605851956985),\n",
       " (19.507185639371617, 19.766065283984975),\n",
       " (19.507190935171717, 19.766070976746832),\n",
       " (19.50719539198406, 19.766075767632213),\n",
       " (19.507199142725373, 19.76607979952101),\n",
       " (19.50720229925505, 19.76608319265734),\n",
       " (19.507204955711135, 19.766086048235646),\n",
       " (19.50720719131785, 19.766088451418618),\n",
       " (19.507209072748307, 19.766090473877043),\n",
       " (19.50721065611292, 19.766092175927252),\n",
       " (19.507211988632807, 19.766093608329957),\n",
       " (19.50721311004807, 19.76609481380409),\n",
       " (19.507214053802986, 19.76609582830084),\n",
       " (19.507214848043418, 19.766096682075823),\n",
       " (19.507215516456217, 19.766097400591402),\n",
       " (19.507216078975638, 19.766098005276067),\n",
       " (19.50721655237785, 19.766098514163488),\n",
       " (19.507216950781263, 19.76609894243036),\n",
       " (19.50721728606757, 19.766099302849003),\n",
       " (19.5072175682361, 19.766099606168282),\n",
       " (19.507217805702048, 19.766099861434164),\n",
       " (19.507218005547426, 19.76610007625952),\n",
       " (19.507218173732277, 19.766100257051143),\n",
       " (19.50721831527242, 19.766100409200835),\n",
       " (19.507218434389053, 19.76610053724619),\n",
       " (19.507218534634617, 19.766100645005945),\n",
       " (19.507218618998767, 19.76610073569385),\n",
       " (19.507218689997515, 19.76610081201451),\n",
       " (19.50721874974828, 19.766100876244064),\n",
       " (19.50721880003302, 19.76610093029804),\n",
       " (19.507218842351396, 19.76610097578851),\n",
       " (19.507218877965478, 19.76610101407215),\n",
       " (19.507218907937396, 19.766101046290693),\n",
       " (19.50721893316101, 19.766101073405014),\n",
       " (19.507218954388566, 19.766101096223746),\n",
       " (19.507218972253145, 19.766101115427418),\n",
       " (19.507218987287526, 19.76610113158874),\n",
       " (19.507218999940086, 19.766101145189708),\n",
       " (19.507219010588162, 19.76610115663594),\n",
       " (19.507219019549314, 19.766101166268804),\n",
       " (19.507219027090795, 19.766101174375578),\n",
       " (19.507219033437515, 19.766101181198035),\n",
       " (19.507219038778757, 19.766101186939643),\n",
       " (19.50721904327381, 19.766101191771636),\n",
       " (19.507219047056736, 19.76610119583812),\n",
       " (19.50721905024035, 19.766101199260373),\n",
       " (19.507219052919602, 19.766101202140455),\n",
       " (19.507219055174392, 19.766101204564258),\n",
       " (19.507219057071964, 19.76610120660407),\n",
       " (19.507219058668916, 19.766101208320723),\n",
       " (19.50721906001287, 19.76610120976542),\n",
       " (19.507219061143907, 19.766101210981237),\n",
       " (19.50721906209576, 19.766101212004436),\n",
       " (19.507219062896816, 19.76610121286554),\n",
       " (19.507219063570965, 19.76610121359022),\n",
       " (19.50721906413831, 19.766101214200095),\n",
       " (19.507219064615775, 19.76610121471335),\n",
       " (19.507219065017598, 19.76610121514529),\n",
       " (19.50721906535576, 19.7661012155088),\n",
       " (19.50721906564035, 19.76610121581472),\n",
       " (19.507219065879852, 19.76610121607218),\n",
       " (19.50721906608141, 19.766101216288845),\n",
       " (19.50721906625104, 19.76610121647119),\n",
       " (19.507219066393795, 19.766101216624644),\n",
       " (19.507219066513933, 19.76610121675379),\n",
       " (19.50721906661504, 19.766101216862474),\n",
       " (19.507219066700127, 19.76610121695394),\n",
       " (19.507219066771736, 19.766101217030915),\n",
       " (19.507219066832, 19.766101217095695),\n",
       " (19.507219066882715, 19.766101217150215),\n",
       " (19.507219066925398, 19.766101217196095),\n",
       " (19.507219066961316, 19.766101217234706),\n",
       " (19.507219066991546, 19.7661012172672),\n",
       " (19.507219067016987, 19.766101217294548),\n",
       " (19.507219067038395, 19.766101217317562),\n",
       " (19.50721906705641, 19.76610121733693),\n",
       " (19.507219067071574, 19.766101217353228),\n",
       " (19.507219067084336, 19.766101217366945),\n",
       " (19.507219067095075, 19.76610121737849),\n",
       " (19.507219067104113, 19.766101217388208),\n",
       " (19.50721906711172, 19.766101217396383),\n",
       " (19.507219067118122, 19.766101217403264),\n",
       " (19.507219067123508, 19.766101217409055),\n",
       " (19.50721906712804, 19.76610121741393),\n",
       " (19.507219067131857, 19.76610121741803),\n",
       " (19.50721906713507, 19.766101217421483),\n",
       " (19.507219067137772, 19.766101217424385),\n",
       " (19.507219067140046, 19.766101217426833),\n",
       " (19.50721906714196, 19.76610121742889),\n",
       " (19.50721906714357, 19.766101217430624),\n",
       " (19.507219067144923, 19.766101217432077),\n",
       " (19.507219067146064, 19.766101217433302),\n",
       " (19.507219067147023, 19.766101217434333),\n",
       " (19.50721906714783, 19.766101217435203),\n",
       " (19.507219067148508, 19.76610121743593),\n",
       " (19.50721906714908, 19.766101217436546),\n",
       " (19.507219067149563, 19.76610121743706),\n",
       " (19.50721906714997, 19.7661012174375),\n",
       " (19.50721906715031, 19.766101217437868),\n",
       " (19.507219067150597, 19.766101217438173),\n",
       " (19.50721906715084, 19.766101217438436),\n",
       " (19.50721906715104, 19.766101217438653),\n",
       " (19.507219067151212, 19.766101217438838),\n",
       " (19.507219067151357, 19.76610121743899),\n",
       " (19.50721906715148, 19.76610121743912),\n",
       " (19.50721906715158, 19.766101217439232),\n",
       " (19.507219067151667, 19.766101217439324),\n",
       " (19.507219067151738, 19.766101217439402),\n",
       " (19.507219067151798, 19.766101217439466),\n",
       " (19.507219067151848, 19.766101217439523),\n",
       " (19.50721906715189, 19.766101217439566),\n",
       " (19.507219067151926, 19.766101217439605),\n",
       " (19.507219067151958, 19.766101217439637),\n",
       " (19.507219067151983, 19.766101217439665),\n",
       " (19.507219067152004, 19.76610121743969),\n",
       " (19.507219067152022, 19.766101217439708),\n",
       " (19.507219067152036, 19.766101217439726),\n",
       " (19.50721906715205, 19.766101217439736),\n",
       " (19.50721906715206, 19.76610121743975),\n",
       " (19.50721906715207, 19.766101217439758),\n",
       " (19.50721906715208, 19.76610121743977),\n",
       " (19.507219067152086, 19.766101217439775),\n",
       " (19.507219067152093, 19.766101217439783),\n",
       " (19.507219067152096, 19.76610121743979),\n",
       " (19.5072190671521, 19.76610121743979),\n",
       " (19.507219067152104, 19.766101217439793),\n",
       " (19.507219067152107, 19.766101217439797),\n",
       " (19.50721906715211, 19.7661012174398),\n",
       " (19.507219067152114, 19.766101217439804),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807),\n",
       " (19.507219067152114, 19.766101217439807)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations[999]\n",
    "iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our  m  and  b  values both update with each step. Not only that, but with each step, the size of the changes to  m and  b  decrease. This is because they are approaching a best fit line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's include 2 predictors, $x_1$ and $x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we generated a problem where we have 2 predictors. We generated data such that the best fit line is around $\\hat y = 3x_1 -4x_2 +2$, noting that there is random noise introduced, so the final result will never be exactly that. Let's build what we built previously, but now create a `step_gradient` function that can take an *arbitrary* number of predictors (so the function should be able to include more than 2 predictors as well). Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(11)\n",
    "\n",
    "x1 = np.random.rand(100,1).reshape(100)\n",
    "x2 = np.random.rand(100,1).reshape(100)\n",
    "y_randterm = np.random.normal(0,0.2,100)\n",
    "y = 2+ 3* x1+ -4*x2 + y_randterm\n",
    "\n",
    "data = np.array([y, x1, x2])\n",
    "data = np.transpose(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "ax1.set_title('x_1')\n",
    "ax1.plot(x1, y, '.b')\n",
    "ax2.set_title('x_2')\n",
    "ax2.plot(x2, y, '.b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `step_gradient` function below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, for our gradients, when having multiple predictors $x_j$ with $j \\in 1,\\ldots, k$\n",
    "\n",
    "$$ \\frac{dJ}{dm_j}J(m_j,b) = -2\\sum_{i = 1}^n x_{j,i}(y_i - (\\sum_{j=1}^km{x_{j,i}} + b)) = -2\\sum_{i = 1}^n x_{j,i}*\\epsilon_i$$\n",
    "$$ \\frac{dJ}{db}J(m_j,b) = -2\\sum_{i = 1}^n(y_i - (\\sum_{j=1}^km{x_{j,i}} + b)) = -2\\sum_{i = 1}^n \\epsilon_i $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'll have one gradient per predictor along with the gradient for the intercept!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(b_current, m_current ,points):\n",
    "    b_gradient = 0\n",
    "    m_gradient = np.zeros(len(m_current))\n",
    "    learning_rate = .1\n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        y = points[i][0]\n",
    "        x = points[i][1:(len(m_current)+1)] \n",
    "        b_gradient += -(1/N)  * (y -  (sum(m_current * x) + b_current))\n",
    "        m_gradient += -(1/N) * x * (y -  (sum(m_current * x) + b_current))\n",
    "    new_b = b_current - (learning_rate * b_gradient)\n",
    "    new_m = m_current - (learning_rate * m_gradient)\n",
    "    return (new_b, new_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 1 step to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated b 0.13965491088061555\n",
      "updated m [0.093847 0.038762]\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "m = [0,0]\n",
    "updated_b, updated_m = step_gradient(b,m,data)\n",
    "print('updated b', updated_b)\n",
    "print('updated m', updated_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply 500 steps to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "m = [0,0]\n",
    "for i in range(500):\n",
    "    iteration = step_gradient(b,m,data)\n",
    "    b = iteration[0]\n",
    "    m = []\n",
    "    for j in range(len(iteration)):\n",
    "        m.append(iteration[1][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.944428332442866, array([2.995890, -3.911055]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - optional\n",
    "\n",
    "Try your own gradient descent algorithm on the Boston Housing data set, and compare with the result from scikit learn!\n",
    "Be careful to test on a few continuous variables at first, and see how you perform. Scikit learn has built-in \"regularization\" parameters to make optimization more feasible for many parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this section, we saw our gradient descent formulas in action.  The core of the gradient descent functions are understanding the two lines: \n",
    "\n",
    "$$ \\frac{dJ}{dm}J(m,b) = -2\\sum_{i = 1}^n x(y_i - (mx_i + b)) = -2\\sum_{i = 1}^n x_i*\\epsilon_i$$\n",
    "$$ \\frac{dJ}{db}J(m,b) = -2\\sum_{i = 1}^n(y_i - (mx_i + b)) = -2\\sum_{i = 1}^n \\epsilon_i $$\n",
    "    \n",
    "Which both look to the errors of the current regression line for our dataset to determine how to update the regression line next.  These formulas came from our cost function, $J(m,b) = \\sum_{i = 1}^n(y_i - (mx_i + b))^2 $, and using the gradient to find the direction of steepest descent.  Translating this into code, and seeing how the regression line continued to improve in alignment with the data, we saw the effectiveness of this technique in practice. Additionally, we saw how you can extend the gradient descent algorithm to multiple predictors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
